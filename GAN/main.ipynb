{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device, torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in data and definig utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/cats_GAN'\n",
    "batch_size = 512\n",
    "im_size = 64\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "\n",
    "def load_transformed_dataset(im_size: int=64):\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize((im_size, im_size)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x * 2 - 1)\n",
    "            ])\n",
    "\n",
    "    return datasets.ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "def denorm(image):\n",
    "    return (image + 1) / 2\n",
    "\n",
    "def show_sample_images(images):\n",
    "    n_samples = min(images.size(0), 64)\n",
    "    n_row = 8\n",
    "    n_col = n_samples // n_row\n",
    "\n",
    "    images = denorm(images[:n_samples])\n",
    "    _, axes = plt.subplots(n_row, n_col, figsize=(8, 8))\n",
    "    plt.suptitle(\"Sample cats from the dataset\", fontsize=16)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        image = images[i]\n",
    "        ax.imshow(image.permute(1, 2, 0))\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.show()\n",
    "\n",
    "def cross_entropy_loss(logits, labels):\n",
    "    return F.binary_cross_entropy_with_logits(logits, labels)\n",
    "\n",
    "def get_noise(n_batch, latent_size):\n",
    "    return torch.randn(n_batch, latent_size, device=device)\n",
    "\n",
    "def visualize_images(images, n_rows=8, n_cols=8, title=None):\n",
    "    images = (images / 2 + 0.5).clamp(0, 1)  # Rescale to [0, 1] range and clamp\n",
    "    cmap = 'viridis'\n",
    "\n",
    "    _, axes = plt.subplots(n_rows, n_cols, figsize=(n_rows, n_cols))\n",
    "    for i in range(n_rows):\n",
    "        for j in range(n_cols):\n",
    "            ax = axes[i, j]\n",
    "            image = images[i * n_cols + j]\n",
    "            image = image.permute(1, 2, 0)\n",
    "            ax.imshow(image.cpu().detach().numpy(), cmap=cmap)\n",
    "            ax.axis(\"off\")\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    if title:\n",
    "        plt.suptitle(title, fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "def plot_learning_curve(g_loss_history, d_g_z_loss_history, d_x_loss_history, d_loss_history):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.plot(g_loss_history, label='Generator', alpha=0.7)\n",
    "    plt.plot(d_g_z_loss_history, label='Discriminator (Generated)', alpha=0.7)\n",
    "    plt.plot(d_x_loss_history, label='Discriminator (Real)', alpha=0.7)\n",
    "    plt.plot(d_loss_history, label='Discriminator Total', alpha=0.7)\n",
    "    plt.xlabel('Ilość iteracji')\n",
    "    plt.ylabel('Wartość funkcji straty')\n",
    "    plt.legend()\n",
    "    plt.title('Krzywe uczenia')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "data = load_transformed_dataset()\n",
    "dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "for batch in dataloader:\n",
    "    images, _ = batch\n",
    "    show_sample_images(images)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator and Discriminator models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_size=128, n_c=3):\n",
    "        super(Generator, self).__init__()\n",
    "        # in: [{batch_size}, {latent_size}]\n",
    "        self.linear = nn.Linear(latent_size, 512 * 4 * 4)\n",
    "        self.norm_1 = nn.BatchNorm2d(512)\n",
    "        self.relu_1 = nn.LeakyReLU(0.2)\n",
    "        # out: [{batch_size}, 512, 4, 4]\n",
    "\n",
    "        self.conv_layer_2 = nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1)\n",
    "        self.norm_2 = nn.BatchNorm2d(256)\n",
    "        self.relu_2 = nn.LeakyReLU(0.2)\n",
    "        # out: [{batch_size}, 256, 8, 8]\n",
    "\n",
    "        self.conv_layer_3 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1)\n",
    "        self.norm_3 = nn.BatchNorm2d(128)\n",
    "        self.relu_3 = nn.LeakyReLU(0.2)\n",
    "        # out: [{batch_size}, 128, 16, 16]\n",
    "\n",
    "        self.conv_layer_4 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)\n",
    "        self.norm_4 = nn.BatchNorm2d(64)\n",
    "        self.relu_4 = nn.LeakyReLU(0.2)\n",
    "        # out: [{batch_size}, 64, 32, 32]\n",
    "\n",
    "        self.output_layer = nn.ConvTranspose2d(64, n_c, kernel_size=4, stride=2, padding=1)\n",
    "        # out: [{batch_size}, 3, 64, 64]\n",
    "\n",
    "    def forward(self, input_layer):\n",
    "        h = self.linear(input_layer)\n",
    "        h = h.view(-1, 512, 4, 4)\n",
    "        h = self.norm_1(h)\n",
    "        h = self.relu_1(h)\n",
    "\n",
    "        h = self.conv_layer_2(h)\n",
    "        h = self.norm_2(h)\n",
    "        h = self.relu_2(h)\n",
    "\n",
    "        h = self.conv_layer_3(h)\n",
    "        h = self.norm_3(h)\n",
    "        h = self.relu_3(h)\n",
    "\n",
    "        h = self.conv_layer_4(h)\n",
    "        h = self.norm_4(h)\n",
    "        h = self.relu_4(h)\n",
    "\n",
    "        x = self.output_layer(h)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, image_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # in: [{batch_size}, 3, 64, 64]\n",
    "        self.conv_1 = nn.Conv2d(3, image_size, kernel_size=4, stride=2, padding=1)\n",
    "        self.norm_1 = nn.BatchNorm2d(image_size)\n",
    "        self.leaky_relu_1 = nn.LeakyReLU(0.2)\n",
    "        # out [{batch_size}, image_size, 32, 32]\n",
    "\n",
    "        self.conv_2 = nn.Conv2d(image_size, 2 * image_size, kernel_size=4, stride=2, padding=1)\n",
    "        self.norm_2 = nn.BatchNorm2d(2 * image_size)\n",
    "        self.leaky_relu_2 = nn.LeakyReLU(0.2)\n",
    "        # out [{batch_size}, 2 * image_size, 16, 16]\n",
    "\n",
    "        self.conv_3 = nn.Conv2d(2 * image_size, 4 * image_size, kernel_size=4, stride=2, padding=1)\n",
    "        self.norm_3 = nn.BatchNorm2d(4 * image_size)\n",
    "        self.leaky_relu_3 = nn.LeakyReLU(0.2)\n",
    "        # out [{batch_size}, 4 * image_size, 8, 8]\n",
    "\n",
    "        self.conv_4 = nn.Conv2d(4 * image_size, 1, kernel_size=8, stride=1, padding=0)\n",
    "        self.norm_4 = nn.BatchNorm2d(8 * image_size)\n",
    "        self.leaky_relu_4 = nn.LeakyReLU(0.2)\n",
    "        # out [{batch_size}, 1, 1, 1]\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.output_layer = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, input_layer):\n",
    "        h = self.conv_1(input_layer)\n",
    "        h = self.leaky_relu_1(h)\n",
    "\n",
    "        h = self.conv_2(h)\n",
    "        h = self.norm_2(h)\n",
    "        h = self.leaky_relu_2(h)\n",
    "\n",
    "        h = self.conv_3(h)\n",
    "        h = self.norm_3(h)\n",
    "        h = self.leaky_relu_3(h)\n",
    "\n",
    "        h = self.conv_4(h)\n",
    "        h = self.leaky_relu_4(h)\n",
    "\n",
    "        h = self.flatten(h)\n",
    "        x = self.output_layer(h)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize parameters for GAN model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_h, n_w, n_c = [im_size, im_size, 3]\n",
    "latent_size = 128\n",
    "n_batch = 1000\n",
    "lr = 2.5e-4\n",
    "epochs = 10000\n",
    "noise_vector = get_noise(n_batch, latent_size).to(device)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(latent_size=latent_size).to(device)\n",
    "discriminator = Discriminator(im_size).to(device)\n",
    "\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "g_loss_history = []\n",
    "d_g_z_loss_history = []\n",
    "d_x_loss_history = []\n",
    "d_loss_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    noise_vector = get_noise(n_batch, latent_size).to(device)\n",
    "    if epoch % 100 == 0:\n",
    "        generated_images = generator(noise_vector)\n",
    "        visualize_images(generated_images, title=f\"Wygenerowane obrazy po {epoch} epokach\")\n",
    "        if epoch != 0:\n",
    "            plot_learning_curve(g_loss_history, d_g_z_loss_history, d_x_loss_history, d_loss_history)\n",
    "            print(f\"Epoka [{epoch + 1}/{epochs}], g_loss: {g_loss.item()}, d_g_z_loss: {d_g_z_loss.item()},  d_x_loss: {d_x_loss.item()}, d_loss: {d_loss.item()}\")\n",
    "\n",
    "\n",
    "    for batch in tqdm(dataloader, ncols=80, leave=False):\n",
    "        data, _ = batch\n",
    "        data = data.to(device)\n",
    "        \n",
    "        d_optimizer.zero_grad()\n",
    "        d_g_z = discriminator(generator(noise_vector))\n",
    "        d_x = discriminator(data)\n",
    "  \n",
    "        d_g_z_loss = cross_entropy_loss(d_g_z, torch.zeros_like(d_g_z))\n",
    "        d_x_loss = cross_entropy_loss(d_x, torch.ones_like(d_x))\n",
    "        d_loss = (d_g_z_loss + d_x_loss) / 2\n",
    "        \n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        g_optimizer.zero_grad()\n",
    "        g_z = generator(noise_vector)\n",
    "        d_g_z = discriminator(g_z)\n",
    "        g_loss = cross_entropy_loss(d_g_z, torch.ones_like(d_g_z))\n",
    "        \n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        g_loss_history.append(g_loss.item())\n",
    "        d_g_z_loss_history.append(d_g_z_loss.item())\n",
    "        d_x_loss_history.append(d_x_loss.item())\n",
    "        d_loss_history.append(d_loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = generator(get_noise(n_batch, latent_size))\n",
    "visualize_images(images, title=f\"Wygenerowana seria obrazów po {epochs} epokach\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Generative-Modeling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
