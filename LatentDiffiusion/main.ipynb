{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "if len(tf.config.list_physical_devices('GPU')):\n",
    "    print(\"Using GPU\")\n",
    "    gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_visible_devices(gpu_devices[0], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (32, 32)\n",
    "batch_size = 32\n",
    "num_of_stages = 3\n",
    "\n",
    "def custom_preprocess(x):\n",
    "    x = (x - 127.5) / 127.5\n",
    "    return x\n",
    "\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=custom_preprocess, # rescale [0.0 - 255.0] to [-1.0 to 1.0] range\n",
    "    validation_split=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "data_for_stage = []\n",
    "for stage in range(num_of_stages):\n",
    "    image_dir = f'../data/cats_stage_{stage}/'\n",
    "\n",
    "    train_data = image_generator.flow_from_directory(\n",
    "        image_dir,\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        subset='training'\n",
    "    )\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: train_data,\n",
    "        output_signature=tf.TensorSpec(shape=(None, image_size[0], image_size[1], 3), dtype=tf.float32) #RGB images so 3 channels, float32 for GPU acceleration\n",
    "    )\n",
    "\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1000).batch(batch_size)\n",
    "    train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    data_for_stage.append(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent_distribiution(latent_size=128, batch_size=64):\n",
    "    initial_distribution_mean = np.zeros(latent_size)\n",
    "    initial_distribution_stddev = 1.0\n",
    "    initial_latent_distribution = np.random.normal(\n",
    "        initial_distribution_mean, initial_distribution_stddev, (batch_size, latent_size)\n",
    "    ).astype(np.float32)\n",
    "\n",
    "    return initial_latent_distribution\n",
    "\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_c):\n",
    "        super(Generator, self).__init__()\n",
    "        self.n_c = n_c\n",
    "\n",
    "        self.dense1 = tf.keras.layers.Dense(256 * 4 * 4)\n",
    "        self.reshape = tf.keras.layers.Reshape((4, 4, 256))\n",
    "        self.upsample1 = tf.keras.layers.UpSampling2D(size=(2, 2))\n",
    "        self.conv1 = tf.keras.layers.Conv2DTranspose(128, kernel_size=5, padding='same')\n",
    "        self.upsample2 = tf.keras.layers.UpSampling2D(size=(2, 2))\n",
    "        self.conv2 = tf.keras.layers.Conv2DTranspose(64, kernel_size=5, padding='same')\n",
    "        self.upsample3 = tf.keras.layers.UpSampling2D(size=(2, 2))\n",
    "        self.conv3 = tf.keras.layers.Conv2DTranspose(32, kernel_size=5, padding='same')\n",
    "        self.conv4 = tf.keras.layers.Conv2DTranspose(n_c, kernel_size=1, padding='same')\n",
    "    \n",
    "    def generate_images_at_stage(self, Z, stage):\n",
    "        h = tf.nn.leaky_relu(self.dense1(Z), 0.2)\n",
    "        h = self.reshape(h)\n",
    "        h = self.upsample1(h)\n",
    "        h = tf.nn.leaky_relu(self.conv1(h), 0.2)\n",
    "        h = self.upsample2(h)\n",
    "        h = tf.nn.leaky_relu(self.conv2(h), 0.2)\n",
    "        h = self.upsample3(h)\n",
    "        h = tf.nn.leaky_relu(self.conv3(h), 0.2)\n",
    "        \n",
    "        if stage == 1:\n",
    "            x = self.conv4(h)\n",
    "        elif stage == 2:\n",
    "            h = self.upsample3(h)\n",
    "            h = tf.nn.leaky_relu(self.conv3(h), 0.2)\n",
    "        elif stage == 3:\n",
    "            h = self.upsample3(h)\n",
    "            h = tf.nn.leaky_relu(self.conv3(h), 0.2)\n",
    "\n",
    "        x = self.conv4(h)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_updates_total = 100\n",
    "lr = 0.0002\n",
    "\n",
    "noise_samples = get_latent_distribiution()\n",
    "generator = Generator(n_c=3)  \n",
    "g_optimizer = tf.optimizers.Adam(learning_rate=lr, beta_1=0.5)\n",
    "g_vars = generator.trainable_variables\n",
    "\n",
    "g_loss_history = []\n",
    "\n",
    "for n_updates in tqdm(range(n_updates_total), ncols=80, leave=False):\n",
    "    true_images_stage_1 = data_for_stage[0].next()\n",
    "    true_images_stage_2 = data_for_stage[1].next()\n",
    "    true_images_stage_3 = data_for_stage[2].next()\n",
    "\n",
    "    generated_images_stage_1 = generator.generate_images_at_stage(noise_samples, stage=1)\n",
    "    generated_images_stage_2 = generator.generate_images_at_stage(noise_samples, stage=2)\n",
    "    generated_images_stage_3 = generator.generate_images_at_stage(noise_samples, stage=3)\n",
    "    \n",
    "    g_loss_stage_1 = mse_loss(generated_images_stage_1, true_images_stage_1)\n",
    "    g_loss_stage_2 = mse_loss(generated_images_stage_2, true_images_stage_2)\n",
    "    g_loss_stage_3 = mse_loss(generated_images_stage_3, true_images_stage_3)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        g_loss = g_loss_stage_1 + g_loss_stage_2 + g_loss_stage_3\n",
    "\n",
    "    g_gradients = tape.gradient(g_loss, g_vars)\n",
    "    g_optimizer.apply_gradients(zip(g_gradients, g_vars))\n",
    "    \n",
    "    if n_updates % 100 == 0:\n",
    "        g_loss_history.append(g_loss)\n",
    "    \n",
    "    if n_updates % 1000 == 0:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
