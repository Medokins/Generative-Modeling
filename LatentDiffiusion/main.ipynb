{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device, torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/cats_GAN'\n",
    "batch_size = 5\n",
    "im_size = 64\n",
    "\n",
    "def load_transformed_dataset(test_split):\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize((im_size, im_size)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x * 2 - 1)\n",
    "            ])\n",
    "\n",
    "    dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "    test_size = int(test_split * len(dataset))\n",
    "    train_size = len(dataset) - test_size\n",
    "\n",
    "    train, test = random_split(dataset, [train_size, test_size])\n",
    "    return torch.utils.data.ConcatDataset([train, test])\n",
    "\n",
    "def denorm(image):\n",
    "    return (image + 1) / 2\n",
    "\n",
    "def show_sample_images(images):\n",
    "    n_samples = min(images.size(0), 64)\n",
    "    n_row = int(np.sqrt(batch_size))\n",
    "    n_col = n_samples // n_row\n",
    "\n",
    "    images = denorm(images[:n_samples])\n",
    "    _, axes = plt.subplots(n_row, n_col, figsize=(8, 8))\n",
    "    plt.suptitle(\"Sample cats from the dataset\", fontsize=16)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        image = images[i]\n",
    "        ax.imshow(image.permute(1, 2, 0))\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.show()\n",
    "\n",
    "def show_forward_diffusion(image, title=None):\n",
    "    if len(image.shape) == 4:\n",
    "        image = image[0, :, :, :] \n",
    "\n",
    "    image = denorm(image)\n",
    "    image = image.permute(1, 2, 0)\n",
    "    image = image.clip(0, 1)\n",
    "\n",
    "    if title:\n",
    "        plt.suptitle(title, fontsize=16)\n",
    "\n",
    "    plt.imshow(image.cpu())\n",
    "\n",
    "def show_tensor_images(images, title=None):\n",
    "    n_images = images.shape[0]\n",
    "    n_columns = int(np.sqrt(n_images))\n",
    "    n_rows = n_images // n_columns + (1 if n_images % n_columns != 0 else 0)\n",
    "\n",
    "    _, axes = plt.subplots(n_rows, n_columns, figsize=(15, 15))\n",
    "    \n",
    "    if title:\n",
    "        plt.suptitle(title, fontsize=16)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < n_images:\n",
    "            image = images[i]\n",
    "            image = denorm(image)\n",
    "            image = image.permute(1, 2, 0)\n",
    "            image = image.clip(0, 1)\n",
    "            ax.imshow(image.cpu())\n",
    "            ax.axis('off')\n",
    "\n",
    "    for i in range(n_images, n_columns * n_rows):\n",
    "        axes.flat[i].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "data = load_transformed_dataset(test_split=0.2)\n",
    "dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for batch in dataloader:\n",
    "    images, _ = batch\n",
    "    show_sample_images(images)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diffusion:\n",
    "    def __init__(self, T=500, Beta_1=0.0001, Beta_T=0.02, im_size=im_size):\n",
    "        self.T = T\n",
    "        self.Beta_1 = Beta_1\n",
    "        self.Beta_T = Beta_T\n",
    "        self.im_size = im_size\n",
    "        self.betas = self.noice_schedule() \n",
    "        self.alphas = 1 - self.betas                                             # αt:= 1 − βt\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, axis=0)                 # α¯t:= Πt s=1 αs\n",
    "                \n",
    "    def noice_schedule(self):\n",
    "        return torch.linspace(self.Beta_1, self.Beta_T, self.T).to(device)\n",
    "\n",
    "    def forward_diffusion(self, x_0, t):\n",
    "        # x_0 is the original image without noise\n",
    "        # t is the iteration number of adding noise\n",
    "        noise = torch.randn_like(x_0)\n",
    "        sqrt_alphas_ = torch.sqrt(self.alphas_cumprod[t])[:, None, None, None]\n",
    "        one_minus_sqrt_alphas_ = torch.sqrt(1 - self.alphas_cumprod[t])[:, None, None, None]\n",
    "\n",
    "        return sqrt_alphas_.to(device) * x_0.to(device) + one_minus_sqrt_alphas_.to(device) * noise.to(device), noise.to(device)\n",
    "\n",
    "    def random_timestamps(self, n):\n",
    "        return torch.randint(low=1, high=self.T, size=(n, ))\n",
    "\n",
    "    def sample(self, model, n):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn((n, 3, im_size, im_size)).to(device)            # create random noise iamge\n",
    "            for t in tqdm(range(self.T - 1, 0, -1), position=0):\n",
    "                if t > 1:\n",
    "                    noise = torch.randn_like(x)\n",
    "                else:\n",
    "                    noise = torch.zeros_like(x)\n",
    "                    \n",
    "                time_stamps = (torch.ones(n) * t).long().to(device)         # create time stamps\n",
    "                predicted_noise = model(x, time_stamps)\n",
    "                alpha = self.alphas[time_stamps][:, None, None, None]\n",
    "                alpha_overhead = self.alphas_cumprod[time_stamps][:, None, None, None]\n",
    "                beta = self.betas[time_stamps][:, None, None, None]\n",
    "\n",
    "                x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_overhead))) * predicted_noise) + torch.sqrt(beta) * noise\n",
    "        model.train()\n",
    "        x = x.clamp(-1, 1)\n",
    "        return x\n",
    "\n",
    "# x_0 is the original image\n",
    "# x_t is the original image after adding noise \"t\" times\n",
    "# q(x_t | x_t-1) -> return image after \"t\" noise iteration (x_t) on the given previously image (x_t-1)       zwykła funkcja\n",
    "# p(x_t-1 | x_t) -> reverse process, gets image with \"t\" iterations of noise and tries to remove noise       model\n",
    "\n",
    "\n",
    "diffiusion = Diffusion(T=500)\n",
    "\n",
    "num_images = 10\n",
    "stepsize = int(diffiusion.T/num_images)\n",
    "image = next(iter(dataloader))[0]\n",
    "\n",
    "plt.figure(figsize=(20,3))\n",
    "plt.axis('off')\n",
    "for idx in range(0, diffiusion.T, stepsize):\n",
    "    t = torch.Tensor([idx]).type(torch.int64)\n",
    "    plt.subplot(1, num_images+1, int(idx/stepsize) + 1)\n",
    "    img, noise = diffiusion.forward_diffusion(image, t)\n",
    "    show_forward_diffusion(img, title=\"sample image with forward noice diffusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, channels, size):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.size = size\n",
    "        self.mha = nn.MultiheadAttention(channels, 4, batch_first=True)\n",
    "        self.ln = nn.LayerNorm([channels])\n",
    "        self.ff_self = nn.Sequential(\n",
    "            nn.LayerNorm([channels]),\n",
    "            nn.Linear(channels, channels),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(channels, channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.channels, self.size * self.size).swapaxes(1, 2)\n",
    "        x_ln = self.ln(x)\n",
    "        attention_value, _ = self.mha(x_ln, x_ln, x_ln)\n",
    "        attention_value = attention_value + x\n",
    "        attention_value = self.ff_self(attention_value) + attention_value\n",
    "        return attention_value.swapaxes(2, 1).view(-1, self.channels, self.size, self.size)\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None, residual=False):\n",
    "        super().__init__()\n",
    "        self.residual = residual\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(1, mid_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(1, out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.residual:\n",
    "            return F.gelu(x + self.double_conv(x))\n",
    "        else:\n",
    "            return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, emb_dim=256):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, in_channels, residual=True),\n",
    "            DoubleConv(in_channels, out_channels),\n",
    "        )\n",
    "\n",
    "        self.emb_layer = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(\n",
    "                emb_dim,\n",
    "                out_channels\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = self.maxpool_conv(x)\n",
    "        emb = self.emb_layer(t)[:, :, None, None].repeat(1, 1, x.shape[-2], x.shape[-1])\n",
    "        return x + emb\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, emb_dim=256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        self.conv = nn.Sequential(\n",
    "            DoubleConv(in_channels, in_channels, residual=True),\n",
    "            DoubleConv(in_channels, out_channels, in_channels // 2),\n",
    "        )\n",
    "\n",
    "        self.emb_layer = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(\n",
    "                emb_dim,\n",
    "                out_channels\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, skip_x, t):\n",
    "        x = self.up(x)\n",
    "        x = torch.cat([skip_x, x], dim=1)\n",
    "        x = self.conv(x)\n",
    "        emb = self.emb_layer(t)[:, :, None, None].repeat(1, 1, x.shape[-2], x.shape[-1])\n",
    "        return x + emb\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, c_in=3, c_out=3, time_dim=256, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.time_dim = time_dim\n",
    "        self.inc = DoubleConv(c_in, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.sa1 = SelfAttention(128, 32)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.sa2 = SelfAttention(256, 16)\n",
    "        self.down3 = Down(256, 256)\n",
    "        self.sa3 = SelfAttention(256, 8)\n",
    "\n",
    "        self.bot1 = DoubleConv(256, 512)\n",
    "        self.bot2 = DoubleConv(512, 512)\n",
    "        self.bot3 = DoubleConv(512, 256)\n",
    "\n",
    "        self.up1 = Up(512, 128)\n",
    "        self.sa4 = SelfAttention(128, 16)\n",
    "        self.up2 = Up(256, 64)\n",
    "        self.sa5 = SelfAttention(64, 32)\n",
    "        self.up3 = Up(128, 64)\n",
    "        self.sa6 = SelfAttention(64, 64)\n",
    "        self.outc = nn.Conv2d(64, c_out, kernel_size=1)\n",
    "\n",
    "    def pos_encoding(self, t, channels):\n",
    "        inv_freq = 1.0 / (                                              # This tensor contains values that will be used to control the frequency of the sinusoidal pattern.\n",
    "            10000\n",
    "            ** (torch.arange(0, channels, 2, device=self.device).float() / channels)\n",
    "        )\n",
    "        pos_enc_a = torch.sin(t.repeat(1, channels // 2) * inv_freq)    # sine component of the positional encoding. \n",
    "        pos_enc_b = torch.cos(t.repeat(1, channels // 2) * inv_freq)    # cosine component of the positional encoding.\n",
    "        pos_enc = torch.cat([pos_enc_a, pos_enc_b], dim=-1)             # tensor which can be added to the input data or embeddings to provide the model with information about the position or order of elements within the sequence.\n",
    "        return pos_enc\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t = t.unsqueeze(-1).type(torch.float)\n",
    "        t = self.pos_encoding(t, self.time_dim)\n",
    "\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1, t)\n",
    "        x2 = self.sa1(x2)\n",
    "        x3 = self.down2(x2, t)\n",
    "        x3 = self.sa2(x3)\n",
    "        x4 = self.down3(x3, t)\n",
    "        x4 = self.sa3(x4)\n",
    "\n",
    "        x4 = self.bot1(x4)\n",
    "        x4 = self.bot2(x4)\n",
    "        x4 = self.bot3(x4)\n",
    "\n",
    "        x = self.up1(x4, x3, t)\n",
    "        x = self.sa4(x)\n",
    "        x = self.up2(x, x2, t)\n",
    "        x = self.sa5(x)\n",
    "        x = self.up3(x, x1, t)\n",
    "        x = self.sa6(x)\n",
    "        output = self.outc(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "epochs = 100\n",
    "model = UNet().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "mse = nn.MSELoss()\n",
    "diffusion = Diffusion(T=500)\n",
    "\n",
    "l = len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    tqdm_object = tqdm(dataloader)\n",
    "    for images, _ in tqdm_object:\n",
    "        images = images.to(device)\n",
    "        t = diffusion.random_timestamps(images.shape[0]).to(device)\n",
    "        x_t, noise = diffusion.forward_diffusion(images, t)\n",
    "        predicted_noise = model(x_t, t)\n",
    "        loss = mse(noise, predicted_noise)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tqdm_object.set_postfix(MSE=loss.item())\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        sampled_images = diffusion.sample(model, n=4)\n",
    "        show_tensor_images(sampled_images, title=f\"Sample images after {epoch} epochs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_images = diffusion.sample(model, n=9)\n",
    "show_tensor_images(sampled_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
